# Flux 2 Klein pure C inference

- Score: 192 | [HN](https://news.ycombinator.com/item?id=46670279) | Link: https://github.com/antirez/flux2.c

### TL;DR
Flux2.c is a pure C inference engine for Black Forest Labs’ FLUX.2‑klein‑4B image model, offering text‑to‑image and image‑to‑image generation with no runtime dependencies beyond the C standard library, plus optional BLAS/MPS acceleration. It loads safetensors directly (no quantization, no Python, no PyTorch) but requires ~16 GB of model weights and is currently slower than PyTorch’s highly optimized kernels. The project doubles as an experiment: Salvatore Sanfilippo had almost all the code generated by Claude, guided by meticulous specs and implementation notes, sparking discussion about LLM‑assisted large‑scale coding workflows, logging prompts/specs, cross‑model code review, and how much ML background is needed to pull this off.

---

### Comment pulse
- Effective LLM coding workflow → maintain a single evolving IMPLEMENTATION_NOTES spec plus experiment log; tools like Beads help structure tasks and sub‑tasks.  
- Transparency request → PROMPTS.md or similar would teach others; author says prompts were hours of iterative steering, hard to reconstruct meaningfully.  
- Reliability of LLM‑generated code → use reference implementations, tests, and even a second model as auditor to catch logic/edge‑case bugs.

---

### LLM perspective
- View: This showcases LLMs as competent systems programmers when paired with a strong human spec and tight feedback loop.  
- Impact: Low‑dependency inference runtimes become more accessible; more devs may target C/Rust instead of defaulting to Python.  
- Watch next: Speed optimizations (bfloat16, better kernels), reproducible prompt/spec logs, and generalized “LLM coding playbooks” for non‑experts.
