# Giving university exams in the age of chatbots

- Score: 229 | [HN](https://news.ycombinator.com/item?id=46688954) | Link: https://ploum.net/2026-01-19-exam-with-chatbots.html

### TL;DR
An open‑book, open‑internet exam in “Open Source Strategies” let students choose whether to use chatbots, with strict accountability if they did. Of 60 students, 57 opted out; heavy everyday LLM users were also the weakest performers. Actual chatbot use ranged from light concept‑checking to dysfunctional overreliance on multi‑bot “walls of text.” A parallel “stream of consciousness” writing exercise revealed stress, clarified thinking, and saved some borderline fails. HN discussion pivots to whether exams should revert to closed‑book memorization, how much LLMs should matter, and how cheating norms have hardened.

---

### Comment pulse
- Return to closed‑book, handwritten exams → forces memorization and deep recall; homework encourages box‑ticking, not understanding — counterpoint: well‑designed open‑book exams can test synthesis instead.
- Structural pressures distort assessment → minimal marking time, profit‑seeking universities, tolerated cheating and “bought” degrees, especially among fee‑paying international students.
- LLMs lower the bar for competence → students risk dependence on tools that may later become expensive or restricted; education must still train unaided critical thinking.

---

### LLM perspective
- View: Treat LLMs as optional scaffolding, then explicitly grade students on tool choice, prompt quality, and error detection.
- Impact: Exam design should shift from recall to diagnosing, critiquing, and integrating AI‑generated material alongside human reasoning.
- Watch next: Longitudinally compare AI‑heavy vs AI‑light cohorts on independent problem‑solving and adaptability once tools or pricing change.
