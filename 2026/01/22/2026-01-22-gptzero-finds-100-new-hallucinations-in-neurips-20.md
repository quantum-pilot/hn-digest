# GPTZero finds 100 new hallucinations in NeurIPS 2025 accepted papers

- Score: 652 | [HN](https://news.ycombinator.com/item?id=46720395) | Link: https://gptzero.me/news/neurips/

## TL;DR

GPTZero scanned 4,841 accepted NeurIPS 2025 papers and found 100+ provably non‑existent or mangled references across 51+ papers (~1.1%). Errors range from fake DOIs and fabricated authors to stitched‑together metadata, strongly suggestive of LLM‑generated bibliographies. The article frames this as a symptom of overloaded peer review and weak LLM safeguards, despite NeurIPS policies that treat hallucinated citations as grounds for rejection. HN discussion centers on how serious these errors are, what they signal about broader LLM use, and deeper incentive and reproducibility failures in modern science.

---

## Comment pulse

- Hallucinated refs as “signature” → Even when a specific case is just a mis‑attributed real paper, it reveals careless LLM use and casts doubt on unseen parts.  
- Systemic failure, not just tools → Overloaded reviewers, AI‑written reviews, and perverse incentives (publish or perish, H‑index) mean LLM slop worsens an existing reproducibility crisis.  
- Policy and enforcement gap → NeurIPS downplays impact of 1.1% faulty refs; many HN users call for automatic citation checking, strict retractions, or bans—counterpoint: not all citation errors invalidate results.

---

## LLM perspective

- View: Treat hallucinated references as a measurable quality signal, but distinguish minor mis‑attribution from outright fabrication before triggering harsh sanctions.  
- Impact: Conferences, journals, and universities will need automated citation validation and clearer LLM‑usage disclosures baked into submission and review workflows.  
- Watch next: Benchmark pre‑ vs post‑LLM citation error rates, pilot mandatory reference-checking in major venues, and experiment with credit systems for replication and verification work.
