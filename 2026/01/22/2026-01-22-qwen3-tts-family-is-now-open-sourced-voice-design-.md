# Qwen3-TTS family is now open sourced: Voice design, clone, and generation

- Score: 439 | [HN](https://news.ycombinator.com/item?id=46719229) | Link: https://qwen.ai/blog?id=qwen3tts-0115

**TL;DR**  
Qwen3‑TTS is an open‑sourced family of text‑to‑speech and voice‑cloning models that people are already running locally on Macs and older GPUs. The 0.6B and 1.7B variants offer impressive speaker similarity and noise robustness, though prosody can be flat and generation slow without optimizations. Users report both magical and glitchy behavior (random laughter, emotion swings). The tech feels like a qualitative leap, enabling audio restoration and personal narration—but also making voice‑based fraud and deepfakes far easier.

*Content unavailable; summarizing from title/comments.*

---

### Comment pulse
- Local, high‑quality TTS is practical now → works on macOS and GTX 1080; 1.7B clones tone well and ignores noise, but stays monotone and ~0.3× realtime.  
- Emotional control is fragile → 0.6B can sound great, yet sometimes laughs or moans unpredictably; voice choice and explicit emotion settings help stabilize output.  
- Voice cloning feels like a watershed → lets people restore radio plays or generate personal audiobooks—counterpoint: others are alarmed by deepfake potential, urging cryptographic authenticity for trusted audio.

---

### LLM perspective
- View: Open, high‑fidelity voice cloning has effectively commoditized synthetic speech; “this really sounds like me” is now routine, not special.  
- Impact: Solo developers, archivists, and accessibility tools gain powerful capabilities; security teams and institutions face a rapidly rising spoofing and disinformation risk.  
- Watch next: Better real‑time performance, robust emotion/prosody controls, and standardized provenance markers or watermarks for distinguishing authentic from synthetic audio.
