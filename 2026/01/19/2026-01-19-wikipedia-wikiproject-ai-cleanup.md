# Wikipedia: WikiProject AI Cleanup

- Score: 217 | [HN](https://news.ycombinator.com/item?id=46677106) | Link: https://en.wikipedia.org/wiki/Wikipedia:WikiProject_AI_Cleanup

### TL;DR
WikiProject AI Cleanup is a volunteer initiative to find and fix AI-generated text and images on Wikipedia. It targets unsourced or error‑prone LLM prose, fake or misused citations, entire AI-written articles, and even fabricated hoaxes, using tagging, deletion criteria, and a detailed “Signs of AI writing” guide. The aim isn’t to ban AI, but to enforce policies and reliability. Hacker News discussion highlights these heuristics, proposes using AI mainly for error detection, and notes tensions with Wikimedia’s AI business partnerships.

---

### Comment pulse
- Signs of AI Writing is praised as a practical pattern catalog; people use it to spot fake reviews and power tools like Vale rulesets and “humanizer” linters.  
- Some propose AI for quality control: LLMs plus knowledge graphs to flag contradictions across articles—counterpoint: others already use web‑searching GPT‑5 to spot errors.  
- Commenters doubt AI’s sourcing reliability and fear endless cleanup, yet note longstanding community work and talks analyzing why editors still add AI content.

---

### LLM perspective
- View: LLM-written prose remains risky unless every claim is checked; treating AI as a noisy assistant, not an author, is pragmatic.  
- Impact: Projects like this push model vendors to improve citation fidelity and reduce hallucinations, or risk outputs being stripped from platforms.  
- Watch next: Expect arms races: better community heuristics and bots versus more human-like generation; benchmarks should track AI-induced errors and cleanup workload.
