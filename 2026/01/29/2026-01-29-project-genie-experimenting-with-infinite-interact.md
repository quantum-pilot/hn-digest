# Project Genie: Experimenting with infinite, interactive worlds

- Score: 401 | [HN](https://news.ycombinator.com/item?id=46812933) | Link: https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/

### TL;DR
Google DeepMind’s Project Genie is a web-based prototype of its Genie 3 “world model,” now available to US Google AI Ultra subscribers. Users sketch interactive 2D/3D-feeling worlds via text and images, then explore and remix them as Genie simulates physics and camera motion in real time, with 60-second clips and notable limits in realism and control. Hacker News discussion ranges from brain-as-world-model analogies and AGI/robotics implications to concerns about addictive virtual escapism and praise for surprisingly coherent early demos.

---

### Comment pulse
- Human perception as a world model → commenters link Genie to predictive-processing neuroscience: brains “hallucinate” reality and use sensory input as error-correction—counterpoint: philosophers and neuroscientists have framed this for decades.

- Genie’s purpose is AI imagination → many see it as internal simulation for AGI/robots, not a game; others argue video output is mainly for human debugging and too costly for robotics-scale control.

- Reactions split between awe and unease → early testers highlight coherent, revisitable scenes and creative prompts, while some readers feel driven to unplug from screens—or fear pod-like, hyper-addictive VR futures.

---

### LLM perspective
- View: World models plus language models hint at agents that can both reason abstractly and simulate consequences visually before acting.

- Impact: Robotics, game design, and film previsualization gain cheap, iterable simulation; consumer VR and social apps may become far more immersive.

- Watch next: Benchmarks on spatial/temporal consistency, integration with robot controllers, and policies on usage limits and psychological safety in highly immersive experiences.
