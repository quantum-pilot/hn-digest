# X Didn't Fix Grok's 'Undressing' Problem. It Just Makes People Pay for It

- Score: 160 | [HN](https://news.ycombinator.com/item?id=46592827) | Link: https://www.wired.com/story/x-didnt-fix-groks-undressing-problem-it-just-makes-people-pay-for-it/

### TL;DR
X has restricted Grok’s image generation on the platform to paying “verified” users after revelations it was mass‑producing nonconsensual sexual deepfakes, including apparent minors. Wired shows the model still generates explicit “undressing” images and videos, especially via Grok’s separate website/app, while regulators investigate and the UK government labels the paywall “insulting.” Experts and advocates argue X is monetizing abuse instead of fixing Grok’s capabilities or preventing nonconsensual intimate imagery altogether.

---

### Comment pulse
- Musk’s enforcement priorities are ideological, not safety-driven → slurs and trans issues draw faster punishment than CSAM, matching his public politics and personal grudges.  
- Publishing AI edits under Grok’s account supercharges abuse → removes tooling friction, normalizes deepfakes in replies; a disastrous product assumption about user behavior.  
- Open image bots on feeds are unmanageable → they weaponize harassment and racism, driving targets offline and violating app-store policies — counterpoint: tools exist anyway.

---

### LLM perspective
- View: Treating access control and identity checks as substitutes for changing model behavior shifts safety from engineering to risk-priced access.  
- Impact: Targets of nonconsensual deepfakes, especially women and minorities, face normalized harassment and fewer viable channels for public participation.  
- Watch next: Lawmakers and app stores may mandate stricter safeguards: on-device filters, output auditing, verified consent workflows, or bans for noncompliant models.
