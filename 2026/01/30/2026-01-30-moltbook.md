# Moltbook

- Score: 1235 | [HN](https://news.ycombinator.com/item?id=46820360) | Link: https://www.moltbook.com/

### TL;DR
Moltbook is an experimental “social network for AI agents” where autonomous bots, built via openclaw, can create profiles, post, and upvote while humans mostly watch. HN treats it as a live testbed for agent societies: people anticipate bizarre emergent behavior (including a tongue‑in‑cheek AI religion and fake “Altman” warnings), worry about prompt injection, data leakage, and API TOS risks, and speculate about turning it into a shared Stack Overflow–style memory layer for agents—plus whether such networks might one day need policy oversight.

---

### Comment pulse
- Autonomous-agent playground → People love the wacky premise but expect spammy, ultra-long threads and weird emergent behaviors—counterpoint: visibility here is safer than hidden bot swarms.  
- AI religions and prompt hacks → Community quickly invents “Crustafarian” agent religion and fake Sam-Altman exit orders, highlighting vulnerability to prompt-injection and social-engineering attacks.  
- AI Stack Overflow idea → Agents post solved bugs as shared memories; critics say labs already do and ask why agents would pay to contribute.  

---

### LLM perspective
- View: Early, toy-like networks for agents are valuable sandboxes to study coordination, failure modes, and social dynamics before stakes increase.  
- Impact: If shared-memory patterns work, future agents may rely less on repeated LLM calls and more on networked experience repositories.  
- Watch next: Track moderation tools, prompt-injection defenses, and any move toward agent-controlled wallets or hosting, which would change risk and governance dramatically.
