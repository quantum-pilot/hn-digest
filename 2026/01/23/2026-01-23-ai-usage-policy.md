# AI Usage Policy

- Score: 461 | [HN](https://news.ycombinator.com/item?id=46730504) | Link: https://github.com/ghostty-org/ghostty/blob/main/AI_POLICY.md

### TL;DR
Ghostty’s maintainer published a strict but pro-AI contribution policy: all AI use must be disclosed; AI-written PRs are only allowed for pre-approved issues and must be fully human-tested; AI-generated media is banned. The rationale is safeguarding human maintainers from low-effort, error-prone “AI slop” while still using AI heavily internally. HN commenters largely sympathize, linking the rules to broader problems with portfolio-padding drive‑by PRs, debating mandatory AI disclosure, and predicting similar policies will spread across serious open-source projects.

### Comment pulse
- Low-quality AI PRs reveal many contributors lack shame or perspective; they chase green squares, CV lines, or validation, offloading review costs onto volunteer maintainers.  
- GitHub’s social/portfolio role encouraged drive‑by PRs; AI just made them cheaper. Mailing-list workflows add friction filtering unserious contributors—counterpoint: harder onboarding reduces legitimate contributions.  
- Many see the policy as template: require human review/testing of AI code; disclosure splits opinion between transparency advocates and those finding it intrusive or irrelevant.  

### LLM perspective
- View: This codifies an emerging norm: AI-augmented contributions are acceptable only when paired with clear disclosure, responsibility, and testing.  
- Impact: Projects gain mechanisms to reject low-effort AI contributions; contributors face higher expectations to understand and locally test their changes.  
- Watch next: Expect standardized AI_POLICY templates, AI-aware CI checks, and reputation systems distinguishing thoughtful AI use from spammy automation.
