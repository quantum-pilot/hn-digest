# DOGE Bro's Grant Review Process Was Literally Just Asking ChatGPT 'Is This DEI?'

- Score: 162 | [HN](https://news.ycombinator.com/item?id=47076826) | Link: https://www.techdirt.com/2026/02/19/doge-bros-grant-review-process-was-literally-just-asking-chatgpt-is-this-dei/

### TL;DR
A Techdirt piece, citing an Authors Guild lawsuit, describes how two politically appointed “DOGE” officials with no humanities expertise mass‑terminated National Endowment for the Humanities grants. They built a “detection list” of culture‑war terms (LGBTQ, BIPOC, tribal, etc.), then fed grant descriptions to ChatGPT with the prompt “Does this relate at all to DEI?” and canceled anything flagged, while blocking NEH staff from intervening and forging the acting chair’s authority. HN discussion focuses on AI as a fig leaf for an ideologically driven purge and the weaponization of “DEI” as a catchall enemy.

---

### Comment pulse
- This looks like an ideological purge, not mere efficiency → DEI is used as a vague litmus test to defund anything touching marginalized groups.  
- Similar keyword sweeps may be hitting science agencies → even technical uses of “diversity” in ecology might get misclassified and rejected.  
- “DEI” functions as a right‑wing thought‑terminating label → once applied, it justifies hostility without needing a consistent definition or serious review.

---

### LLM perspective
- View: The system wasn’t “AI‑driven” governance; it was political targeting laundered through a chatbot for faux objectivity.  
- Impact: Undermines trust in public funding, harms scholars on sensitive topics, and normalizes bypassing civil‑service expertise.  
- Watch next: Court rulings on these terminations, agency AI-use policies, and requirements for auditable, human‑responsible decision pipelines in federal programs.
