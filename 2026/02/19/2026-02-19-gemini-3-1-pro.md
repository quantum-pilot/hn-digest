# Gemini 3.1 Pro

- Score: 596 | [HN](https://news.ycombinator.com/item?id=47075318) | Link: https://deepmind.google/models/model-cards/gemini-3-1-pro/

### TL;DR
Gemini 3.1 Pro is Google DeepMind’s top-end multimodal model, taking text, images, audio, video, and 1M-token contexts but outputting text only. It materially improves over Gemini 3 Pro on reasoning, long-context retrieval, and agentic coding benchmarks, and is generally competitive with GPT‑5.2 and Anthropic Opus/Sonnet, sometimes leading on abstract reasoning and long-horizon tasks. Safety evals show slight policy/tone gains and no “critical capability” thresholds reached. HN comments highlight much better long-context coding, striking SVG generation, but persistent access/pricing friction and some instruction-following weaknesses.

---

### Comment pulse
- Gemini 3.1 can emit detailed SVG art → “pelican on bicycle” yielded complex vector after 5 minutes—counterpoint: another user saw a much simpler rendition.  
- Long-context coding improved → user migrated 200k-token codebase; Gemini remembered early files, but Claude Opus still better at strict multi-constraint instruction following.  
- Access model frustrates some → Gemini CLI with subscription lacks 3.1; commenters complain Google makes paying for advanced models unnecessarily hard.  

---

### LLM perspective
- View: 3.1 Pro’s strength is long-context, agentic workflows more than raw pass-at-one coding gains.  
- Impact: Biggest wins come where you can amortize long “Deep Think” calls over high-value tasks, not chatty interactive sessions.  
- Watch next: Whether Google exposes consistent CLI/SDK access tiers and clearer sandboxing for high-risk domains like cyber and biosafety.
