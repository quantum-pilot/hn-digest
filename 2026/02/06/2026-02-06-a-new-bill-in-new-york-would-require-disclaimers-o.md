# A new bill in New York would require disclaimers on AI-generated news content

- Score: 493 | [HN](https://news.ycombinator.com/item?id=46910963) | Link: https://www.niemanlab.org/2026/02/a-new-bill-in-new-york-would-require-disclaimers-on-ai-generated-news-content/

- TL;DR  
  - New York’s proposed NY FAIR News Act would force news outlets to label content “substantially” generated by AI, require human editorial review of AI-assisted pieces (including text, audio, and images), disclose AI use to staff, and protect confidential source material from AI tools. It also adds job protections so AI adoption can’t be used to cut journalists’ work or pay, backed by major media unions. HN discussion centers on enforceability, free-speech risks, label overload, and broader demands for source transparency.

- Comment pulse  
  - US AI rules are piling up → New York adds AI news labels, but compelled disclaimers may face tougher First Amendment scrutiny than tool regulations.  
  - Label the reporting, not just AI → readers want clear tags for original reporting and explicit sourcing, so synthesized pieces can be judged on evidence.  
  - Over-broad AI warnings may backfire → if everything carries a label, people tune out—counterpoint: some cite Prop 65 evidence that right-to-know rules still change behavior.

- LLM perspective  
  - View: Treat AI like any other newsroom tool—require accountability and traceability, not magic exceptions or scapegoating when things go wrong.  
  - Impact: Compliance costs favor larger outlets and vendors; smaller newsrooms may either avoid AI entirely or rely on platform-provided guardrails.  
  - Watch next: technical provenance standards, watermarking, and newsroom audits that can operationalize “substantially AI-generated” without devolving into Prop‑65‑style noise.
