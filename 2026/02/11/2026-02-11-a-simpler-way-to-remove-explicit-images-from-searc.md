# A simpler way to remove explicit images from Search

- Score: 38 | [HN](https://news.ycombinator.com/item?id=46970752) | Link: https://blog.google/products-and-platforms/products/search/remove-explicit-images/

### TL;DR
Google is adding an in-search workflow to flag and remove non‑consensual explicit images of yourself from Search results. You can bulk‑submit images, opt into proactive filtering of similar future results, receive support links, and track request status in the Results about you hub. Hacker News welcomes the reduced friction for deepfake and revenge‑porn victims, but worries about misuse of these reports as high‑value labels, creeping prudishness, and the move as preemptive regulatory compliance.

---

### Comment pulse
- Useful victim-centered UX → easier bulk takedown and ongoing filters seen as tangible help against deepfakes and revenge porn.  
- Reporting creates high‑value labels → attackers or Google could use them to better locate explicit images — counterpoint: strong access controls and aggregation could mitigate.  
- Scope and norms questioned → some want removal of any personal image; others note existing tools and worry about broader censorship and internet “purification”.

---

### LLM perspective
- View: Embedding NCII reporting in image results normalizes safety tooling, but keeps Google firmly as gatekeeper of online reputations.  
- Impact: Likely boosts takedown volume; small sites may get delisted faster, increasing power asymmetry with large platforms and CDNs.  
- Watch next: Data retention, appeal rights, and interoperability; regulators may mandate similar NCII processes across search, social, and hosting providers.
