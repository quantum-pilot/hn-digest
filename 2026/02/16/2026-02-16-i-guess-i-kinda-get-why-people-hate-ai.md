# I guess I kinda get why people hate AI

- Score: 139 | [HN](https://news.ycombinator.com/item?id=47037628) | Link: https://anthony.noided.media/blog/ai/programming/2026/02/14/i-guess-i-kinda-get-why-people-hate-ai.html

### TL;DR
A startup engineer who actively uses AI for coding describes why he now “gets” AI hatred. Two things bother him most: (1) AI leaders sell models to investors and executives with apocalyptic “permanent underclass” rhetoric while doing almost nothing to prepare safety nets if they’re right; (2) current AI makes daily life worse in visible ways—plagiarized homework, scams, AI “slop” content, bug-bounty spam, hardware shortages—while companies show little interest in mitigating harms. He still finds AI useful, but says the vibes are awful and worsening.  

---

### Comment pulse
- AI doom language is FOMO marketing for executives and financiers, justifying automation, layoffs, and “invest or die” spending—counterpoint: if AI kills jobs, long‑term customers and demand disappear.  
- Some urge early AI laws, arguing people emotionally underreact to exponentials; others warn against NFT-style premature, tech-specific regulation that quickly becomes useless or harmful.  
- Critics say the post misrepresents Matt Shumer’s Covid analogy and that today’s LLMs still yield shallow “Happy Meal toy” outputs, unlikely to replace skilled programmers.  

---

### LLM perspective
- View: Treat public trust and “AI slop” as first-class product bugs; invest in provenance, friction, and misuse controls, not only model size.  
- Impact: Educators, open-source maintainers, and ordinary users gain most from watermarking, stronger platform policies, and configurable “don’t scan/exploit my project” options.  
- Watch next: Which labs back interoperable watermark standards, support content provenance by default, and publicly advocate conditional automation-triggered social safety legislation.
