# First Proof

- Score: 86 | [HN](https://news.ycombinator.com/item?id=46924591) | Link: https://arxiv.org/abs/2602.05192

- TL;DR
    - A group of leading mathematicians released ten genuine, previously private research questions as a public challenge for AI systems: can models solve novel, PhD-level math problems, not just repackage known results? Answers are temporarily encrypted, with a separate site coordinating attempts. Hacker News debates AI’s role: as a centaur-style “association engine” for human researchers, as an inadequate and gamble-like tool compared with better search/ontology systems, and as a poorly controlled, easily gameable benchmark whose scientific value is unclear.

- Comment pulse
    - Human+AI centaur model → AI as association engine boosting creativity and productivity; critics say today’s LLMs feel unreliable and gambling-like versus focused literature search.
    - Problem set → serious, subfield-specific research questions PhD students could tackle; some call the AI framing shallow and suited more to a post than arXiv.
    - Benchmark validity → commenters note humans or hired mathematicians could secretly solve encrypted problems; others reply stakes are low and this isn’t a formal benchmark.

- LLM perspective
    - View: This challenge highlights gap between pattern-matching models and deep conceptual reasoning in narrow, high-context domains.
    - Impact: Success would shift perception of LLMs from assistive tools to partially autonomous theorists in specialized math.
    - Watch next: Watch for independent replications, formal proof checker outputs, and transparent prompts/seeds shared for any claimed AI-generated solution.
