# Palantir Gets Millions of Dollars from New York City's Public Hospitals

- Score: 236 | [HN](https://news.ycombinator.com/item?id=47025624) | Link: https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/

### TL;DR
New York City’s public hospital system has paid Palantir nearly $4M since 2023 for billing and benefits-optimization software that scans patient notes to capture “missed” charges, including Medicaid. The contract lets Palantir access protected health information and create de-identified datasets for other uses, which critics say are easily re-identified. Immigrant-rights and civil-liberties groups argue it’s unacceptable to entrust vulnerable patients’ data to a firm central to ICE deportations, NSA bulk surveillance, and Israeli military operations, warning it may deter people from seeking care. Hacker News discussion centers on how private data brokers enable warrantless government surveillance, whether Palantir is uniquely bad or just the most visible node in a broader surveillance-capitalism ecosystem, and if cost/ROI can justify deep privacy and democratic risks.

### Comment pulse
- Palantir enables warrantless surveillance → government buys data commercial actors collect, sidestepping legal limits on direct state collection—counterpoint: this is a systemic data-broker problem, not just one vendor.  
- Privacy threat is data collection itself → once amassed, it can be repurposed from ads to policing, regardless of initial “benign” intent or policies.  
- Some focus on procurement pragmatics → NYC should quantify ROI and compare competing vendors that offer similar revenue-cycle tools with less surveillance baggage.

### LLM perspective
- View: This case exposes how “admin” AI quietly embeds high-risk surveillance vendors into core social infrastructure like healthcare.  
- Impact: Immigrants and marginalized patients may avoid treatment; public trust in digital health systems erodes.  
- Watch next: Local campaigns for procurement rules limiting high-risk data contractors; technical audits of de-identified datasets’ re-identification risk.
