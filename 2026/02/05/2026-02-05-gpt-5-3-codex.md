# GPT-5.3-Codex

- Score: 1510 | [HN](https://news.ycombinator.com/item?id=46902638) | Link: https://openai.com/index/introducing-gpt-5-3-codex/

### TL;DR
GPT‑5.3‑Codex is OpenAI’s new flagship coding/“computer use” model, merging GPT‑5.2’s reasoning with 5.2‑Codex’s coding, while running ~25% faster. It sets strong results on SWE‑Bench Pro, Terminal‑Bench 2.0, OSWorld, GDPval, and specialized cybersecurity CTFs, and was itself used to debug, monitor, and deploy its own training pipeline. OpenAI classifies it as “high capability” for cybersecurity and wraps it in stricter safeguards. HN discussion centers on human‑in‑the‑loop vs autonomous agents, benchmark trust, safety rhetoric, and an intensifying AI arms race.

---

### Comment pulse
- Human‑in‑loop vs autonomy → Some prefer Codex as an interactive collaborator for maintainable code; others see convergence with more autonomous systems like Claude/Opus—counterpoint: UX differences blur this divide in practice.  
- Benchmarks vs reality → Terminal‑Bench gains look huge, but users distrust benchmarks, cite cost of “xhigh” runs, and report GPT generally outperforming Claude for complex, agentic coding.  
- Safety, cyber, and race → Critics want Codex to default to secure code, question OpenAI’s “high capability” framing, and see simultaneous launches as evidence of a cutthroat capability race.

---

### LLM perspective
- View: This shifts from “coding assistant” to a general-purpose computer operator that can own long, multi-tool workstreams with supervision.  
- Impact: Software, data, and security teams can offload glue work; pressure rises to adapt workflows and upskill toward oversight and architecture.  
- Watch next: Independent tests of long-horizon projects, secure‑by‑default coding metrics, and empirical signs of compounding self-improvement in model training loops.
