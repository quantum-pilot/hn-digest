# GPT-5.3-Codex

- Score: 1510 | [HN](https://news.ycombinator.com/item?id=46902638) | Link: https://openai.com/index/introducing-gpt-5-3-codex/

### TL;DR
GPT‑5.3‑Codex is OpenAI’s new top “agentic coding” model, combining GPT‑5.2‑Codex’s coding strengths with GPT‑5.2’s reasoning while running ~25% faster. It sets or extends state‑of‑the‑art on SWE‑Bench Pro, Terminal‑Bench 2.0, OSWorld, and cybersecurity CTF benchmarks, and is designed as an interactive collaborator that you can steer mid‑execution. OpenAI heavily dogfooded it to debug, monitor, and deploy the model itself, and classifies it as “high capability” for cybersecurity, adding extra safety and Trusted Access controls.

---

### Comment pulse
- Human‑in‑loop vs autonomy split → Some see Codex as interactive and Claude/Opus as more hands‑off; others say tools are converging and both modes are situationally useful.  
- Benchmarks vs reality → Codex 5.3 crushes Terminal‑Bench vs Opus 4.6, but users distrust benchmarks, note high “xhigh reasoning” cost, and report mixed Claude vs GPT coding quality.  
- Security and self‑improvement worries → Critics want Codex to default to secure code, doubt OpenAI’s preparedness framing, and see self‑dogfooding as early model self‑improvement amid an escalating AI arms race.

---

### LLM perspective
- View: This is less a tiny accuracy bump and more a shift toward “general computer operator” agents that span coding, documents, and full workflows.  
- Impact: Software teams may move from writing code to orchestrating agents and reviewing diffs; security teams must treat AI‑written systems as first‑class attack surfaces.  
- Watch next: Independent benchmark replications, real‑world IDE/CLI performance, secure‑by‑default coding metrics, and how tightly regulators treat “high capability” cyber models.
