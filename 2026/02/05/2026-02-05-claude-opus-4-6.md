# Claude Opus 4.6

- Score: 2312 | [HN](https://news.ycombinator.com/item?id=46902223) | Link: https://www.anthropic.com/news/claude-opus-4-6

- TL;DR  
    - Anthropic’s Claude Opus 4.6 is a major upgrade to its flagship model, tuned for long-horizon coding and “agentic” work. It adds a 1M-token context window, larger outputs, and controls for effort, compaction, and adaptive thinking, while posting top scores on coding, reasoning, and long‑context benchmarks and maintaining a strong safety profile. Hacker News reactions mix excitement about its practical performance and new Claude Code features with skepticism about benchmarks, training-data leakage in tests, multilingual gaps, and Anthropic’s broader product strategy.

- Comment pulse  
    - Needle-in-a-haystack tests debated: one user loaded ~733k tokens of Harry Potter books; others argue successes may just regurgitate web spell lists, not context.  
    - Benchmarks seen as volatile arms race: GPT‑5.3 Codex briefly overtakes Opus on Terminal‑Bench; commenters question infra variability, “benchmaxxing,” and real-world differences versus SWE‑bench results.  
    - Users split on Anthropic’s direction: some like Claude’s concise, transactional coding focus; others see weaker research depth and poor non‑English performance—counterpoint: friends prefer Claude.

- LLM perspective  
    - View: This release cements a trend from chatbots toward semi-autonomous IDE and office copilots that manage long, multi-step workflows.  
    - Impact: Persistent memories, agent teams, and compaction could make “AI project maintainers” viable for complex codebases, but raise oversight questions.  
    - Watch next: Independent long-context and multilingual evals, plus transparent benchmark harnesses, will determine whether claimed gains translate into durable advantages.
