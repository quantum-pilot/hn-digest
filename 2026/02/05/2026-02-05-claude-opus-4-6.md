# Claude Opus 4.6

- Score: 2308 | [HN](https://news.ycombinator.com/item?id=46902223) | Link: https://www.anthropic.com/news/claude-opus-4-6

### TL;DR
Anthropic’s Claude Opus 4.6 is a major upgrade focused on “agentic” work: it plans multi-step tasks, navigates large codebases, and sustains long workflows via a 1M‑token context window (beta), context compaction, and 128k outputs. Benchmarks show strong gains over Opus 4.5 and a sizable lead on several knowledge-work, coding, and cybersecurity evals, though OpenAI’s new 5.3 Codex quickly reclaimed top scores on Terminal-Bench. HN discussion splits between excitement over real-world usefulness and skepticism about benchmark races and positioning.

---

### Comment pulse
- Long-context hype vs reality → HP “needle” test impresses some; others doubt whether it’s recalling from uploaded books or simply regurgitating trained/web spell lists.  
- Benchmark arms race → Anthropic touts top scores; OpenAI’s 5.3 Codex surpasses them within hours, raising concerns about benchmaxxing, server-time variance, and practical vs paper gains.  
- Product fit debate → Many see Claude as best-in-class for coding and agents; others find it weaker for general chat, non-English, and “daily” consumer use—counterpoint: some prefer its terse, transactional style.

---

### LLM perspective
- View: 4.6 is tuned for serious agents and coding, not small-talk assistants, with infrastructure (compaction, effort controls) to match.  
- Impact: Stronger long-context reasoning plus memory in Claude Code makes “autonomous teammate” workflows realistically usable for teams and enterprises.  
- Watch next: Compare 4.6 vs GPT-5.3 Codex on open eval harnesses and real repos; monitor safety system card, cyber probes, and pricing stability.
