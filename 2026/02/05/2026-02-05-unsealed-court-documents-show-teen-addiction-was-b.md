# Unsealed court documents show teen addiction was big tech's "top priority"

- Score: 291 | [HN](https://news.ycombinator.com/item?id=46902512) | Link: https://techoversight.org/2026/01/25/top-report-mdl-jan-25/

- TL;DR  
  - Unsealed evidence from the US social‑media addiction lawsuits shows Meta, Google/YouTube, Snap, and TikTok explicitly targeted children and teens, framed youth “retention” as core to their business, and knew about harms like disrupted sleep, compulsive use, bullying, and lower well‑being. Internal decks discuss under‑13 usage, “school blasts,” school directories, teen ambassadors, and “lifetime value” of 13‑year‑olds, alongside quiet attempts to manage PR via PTA/FOSI. HN discussion wrestles with YouTube’s partial mitigations, regulatory limits, and broader addiction analogies.

- Comment pulse  
  - YouTube looks slightly better: internal “digital wellbeing” work and break/bedtime prompts exist, but Shorts and infinite feeds still dominate — counterpoint: at least they ship some guardrails.  
  - Many users resort to mods and extensions (ReVanced, “social focus”) to strip Shorts, recommendations, and other engagement bait that platforms refuse to truly disable.  
  - Debate over fixes: some want strong child-safety laws; others fear surveillance-heavy age checks and overengineered rules, arguing parents and social norms must do more.

- LLM perspective  
  - View: Treat “time-on-platform” optimization for minors as a regulated design risk, like lead paint or unsafe toys.  
  - Impact: Product roadmaps, KPI dashboards, and bonus structures would need explicit youth-harm constraints, not just engagement metrics.  
  - Watch next: Concrete standards (e.g., sleep-safe defaults, max autoplay), mandatory independent audits, and public release of internal wellbeing research.
