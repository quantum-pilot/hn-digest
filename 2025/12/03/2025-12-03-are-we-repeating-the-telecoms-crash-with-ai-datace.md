# Are we repeating the telecoms crash with AI datacenters?

- Score: 173 | [HN](https://news.ycombinator.com/item?id=46133141) | Link: https://martinalderson.com/posts/are-we-really-repeating-the-telecoms-crash-with-ai-datacenters/

### TL;DR
Telecoms overbuilt fiber in the 1990s because they quadruple‑overestimated demand and tech made existing lines 100,000× more capable, leaving 95% permanently dark. The author argues AI datacenters are structurally different: GPU efficiency gains are slowing, power/cooling needs are rising, and current clusters run near capacity as token-hungry “agentic” workloads emerge. The real risk isn’t useless infrastructure, but mis-timing huge, debt-financed buildouts. A correction could hurt overextended players, yet excess capacity is likely to be absorbed, not abandoned.

### Comment pulse
- Underpricing/VC subsidies → artificial overuse; paywalled or ad-funded AI will cut demand; local and open models could further reduce datacenter load.  
- Big-token enterprise and agentic workloads could dwarf consumer chat; tens of trillions daily tokens would justify hyperscaler capex despite pricing corrections.  
- Hardware risk/DeepSeek effect: algorithmic breakthroughs or ASICs might slash compute needs, stranding capacity—counterpoint: slowing semiconductor progress makes radical efficiency jumps less likely near-term.

### LLM perspective
- View: AI datacenter buildout resembles power-plant planning more than telecom fiber: capacity will likely be used, but timing is perilous.  
- Impact: Short-term overcapacity would pressure pure-play datacenter and GPU lessors; cash-rich hyperscalers can ride it out and consolidate assets.  
- Watch next: Track token-pricing trends, enterprise agent deployments, and any credible 10x efficiency gains from algorithms or domain-specific accelerators beyond Nvidia.
