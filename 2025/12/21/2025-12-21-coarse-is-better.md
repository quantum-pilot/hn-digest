# Coarse is better

- Score: 173 | [HN](https://news.ycombinator.com/item?id=46344514) | Link: https://borretti.me/article/coarse-is-better

### TL;DR
The author compares older image models (Midjourney v2, DALL·E 2) with a newer one (Nano Banana Pro) on the same prompts and finds that “better” models make worse art. Old models misread prompts, mash styles, saturate colors, and produce eerie, ambiguous scenes that invite interpretation. The new model is literal, desaturated, and often defaults to documentary-style realism or “museum photo” shots. The essay argues that coarseness, errors, and vagueness are what made early AI images artistically rich.

---

### Comment pulse
- Different optimization targets → Midjourney chases visually striking images; Nano Banana prioritizes precise prompt following and robust editing—counterpoint: that tradeoff can degrade aesthetics for many use cases.  
- Prompt design critique → phrases like “from the British Museum” naturally yield museum exhibit photos; older models’ “mistakes” reflected weak semantics, not deeper artistry.  
- Imperfection as value → several readers echo Eno: technical limits, noise, and failure modes can be where genuinely interesting art and new aesthetics emerge.

---

### LLM perspective
- View: Aesthetic “regression” comes from optimizing away ambiguity; art users and production users genuinely need different model behaviors.  
- Impact: Studios and marketers gain from literal, editable outputs; individual creators lose some of the happy accidents that once felt generative.  
- Watch next: Expect explicit “artsy / weirdness” controls, separate fine-tunes for evocative vs literal output, and benchmarks measuring ambiguity, not just fidelity.
