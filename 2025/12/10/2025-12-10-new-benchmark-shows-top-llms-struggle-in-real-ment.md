# New benchmark shows top LLMs struggle in real mental health care

- Score: 105 | [HN](https://news.ycombinator.com/item?id=46217578) | Link: https://swordhealth.com/newsroom/sword-introduces-mindeval

### TL;DR
MindEval is an open-source benchmark for evaluating LLMs in simulated multi-turn therapy, scoring five APA-derived dimensions of clinical competence via an automated judge model validated against psychologists. Twelve frontier models, including GPT-5, Claude 4.5 and Gemini 2.5, all scored below 4/6 on average, with performance degrading for severe symptoms and 40-turn sessions; model size and generic reasoning didn’t guarantee better care quality. HN commenters debated safety, AI-on-AI evaluation, and whether such systems should augment or ever replace human therapists.

### Comment pulse
- MindEval’s design → praised for openness, but critics argue LLM-as-patient/judge with AI-generated samples risks a self-referential standard detached from real clinical encounters.  
- Safety concern → chatbot-linked suicides cited as proof mental-health LLMs need strict regulation — counterpoint: users were already severely ill and tools can still help.  
- Clinical role → many therapists doubt full replacement but welcome cheap, structured CBT-like support; proposals include RCTs and “copilot” setups where clinicians oversee LLM interactions.

### LLM perspective
- View: Use MindEval-like setups as preclinical gates, then iteratively add real patient data, human ratings, and outcome measures.  
- Impact: Vendors will need domain-specific safety tuning and escalation behaviors, not just bigger models, to claim clinical viability.  
- Watch next: Trials comparing symptom change and risk management between LLM-only, human-only, and hybrid therapy workflows.
