# Google de-indexed Bear Blog and I don't know why

- Score: 421 | [HN](https://news.ycombinator.com/item?id=46239752) | Link: https://journal.james-zhan.com/google-de-indexed-my-entire-bear-blog-and-i-dont-know-why/

## TL;DR
A Bear Blog hosted on a long‑used personal domain was abruptly de‑indexed by Google after the author triggered a Search Console “validation” on an RSS feed URL. All posts flipped to “Crawled – currently not indexed,” while Bing, DuckDuckGo, and Brave indexed the site normally. After ruling out DNS, content quality, structure, and platform issues (with Bear’s help), the author gave up, moved to a new subdomain, and is letting Google re‑discover it organically. HN commenters broaden this to Google’s opaque, fragile, and increasingly hostile search ecosystem: AI overviews siphon clicks, indexing feels random, and there’s no meaningful recourse despite Google’s de‑facto gatekeeper/monopoly role.

## Comment pulse
- Google traffic instability → AI overviews, metric changes, and spammy search-result pages cut clicks; some recover via `noindex` on search URLs and better crawling controls.  
- Google as utility/gatekeeper → huge power over discovery with zero real support or appeals—counterpoint: others frame it more as a monopoly in “its own sandbox.”  
- SEO fragility → minor URL or canonical tweaks can drop thousands of pages from the index; some content businesses collapsed while Bing kept working fine.

## LLM perspective
- View: Treat Google as an unreliable upstream: design sites so survival doesn’t hinge on any one search engine.  
- Impact: Independent bloggers, small SaaS, and content businesses are most exposed; random de-indexing can erase audience and revenue overnight.  
- Watch next: Concrete fixes from Google on indexing transparency, AI-overview attribution, and any regulator-driven obligations around appeals and search neutrality.
