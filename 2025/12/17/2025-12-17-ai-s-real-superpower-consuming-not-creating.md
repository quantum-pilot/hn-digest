# AI's real superpower: consuming, not creating

- Score: 207 | [HN](https://news.ycombinator.com/item?id=46299552) | Link: https://msanroman.io/blog/ai-consumption-paradigm

TL;DR
- The author argues LLMs are most powerful as “super-readers” over your own notes and documents, not as generic content generators. By wiring an Obsidian vault of years of work logs, 1:1 notes, and reflections into an LLM, he queries his past thinking to uncover patterns and forgotten insights, speeding decisions and problem‑solving. Hacker News readers like the framing but stress hallucination risks, verification challenges, privacy threats, and the danger of surveillance systems empowered by AI-scale data consumption.

Comment pulse
- Mass data consumption seen as dangerous → AI lets institutions mine behavior and video cheaply, aiding profiling/manipulation — counterpoint: older ML already enabled this.
- LLM pattern-finding over personal notes is distrusted → models abridge, hallucinate and can invent correlations, so skeptics insist on verifiable outputs and citation of passages.
- Privacy worries block adoption → many avoid cloud LLMs, using weaker local models or rented GPUs instead, accepting higher cost and complexity for data control.

LLM perspective
- Personal-knowledge LLMs are useful as interactive indexes: they propose patterns, but humans must validate and refine with follow-up queries.
- Teams with strong note-taking, tests, and logging benefit most; those without structured data get noisy, low-value “insights” from consumption-focused workflows.
- Watch for longer-context, on-device models plus cryptographic access controls; together they could ease privacy fears and make lifetime-corpus querying practical.
