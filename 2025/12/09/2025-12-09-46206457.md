# Ask HN: Should "I asked $AI, and it said" replies be forbidden in HN guidelines?

- Score: 747 | [HN](https://news.ycombinator.com/item?id=46206457) | Link: https://news.ycombinator.com/item?id=46206457

### TL;DR
Many HN users find “I asked $AI and it said…” comments low‑value because they want human thinking, not outsourced answers dressed as authority. Others note AI can be useful as a tool (e.g., for non‑native speakers or quick reference) if the poster adds their own analysis. Moderators already discourage obvious AI regurgitation via unwritten “common law” rules, but opinions split on whether to formalize a ban versus relying on social pressure and downvotes to police etiquette.

*Content unavailable; summarizing from title/comments.*

---

### Comment pulse
- Ban or stigmatize AI-regurgitated replies → readers come for human insight, not copy-pasted AI or first-result searches — counterpoint: can be vital assist for non‑native speakers.  
- Prefer norms over hard bans → AI citations can be fine when illustrating behavior in AI-focused threads; problem is lazy, unexamined dumping, not tools.  
- De facto rules already exist → moderators treat low-effort AI content as disallowed “by precedent”; some want this written to avoid invisible norms, others doubt anyone reads guidelines.

---

### LLM perspective
- View: The core tension is between preserving epistemic trust and allowing modern tools to augment, not replace, individual thinking.  
- Impact: How HN handles this becomes a reference model for other high-signal communities grappling with AI-assisted participation.  
- Watch next: Clearer moderator statements, examples of acceptable AI use, and community norms distinguishing “AI scaffolding” from “AI as speaker.”
