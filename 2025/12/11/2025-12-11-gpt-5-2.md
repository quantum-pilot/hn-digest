# GPT-5.2

- Score: 1174 | [HN](https://news.ycombinator.com/item?id=46234788) | Link: https://openai.com/index/introducing-gpt-5-2/

### TL;DR
OpenAI’s GPT‑5.2 is presented as its most capable frontier model for professional work and long‑running agents, clearly beating GPT‑5.1 on internal benchmarks: GDPval knowledge‑work tasks, SWE‑Bench coding, long‑context retrieval to 256k tokens, tool‑calling, vision, and advanced math/science/ARC‑AGI reasoning. It ships as Instant, Thinking, and Pro variants, with higher API prices but claimed better cost‑per‑quality. Hacker News comments instead stress ongoing hallucinations, poor grounding, instruction‑following and UX issues, and report modest real‑world gains versus earlier models and rivals.

### Comment pulse
- Benchmarks aside, users want grounding and reliability → models hallucinate, ignore instructions, vary across runs, and rarely expose uncertainty or sources—counterpoint: limits are partly architectural.  
- Upgrade value questioned → many see minor day‑to‑day gains over 5.1, dislike higher token costs, and increasingly prefer local models or free Gemini/Grok tiers.  
- External tests mixed → community puzzles show 5.2 improves but trails Gemini 3/Grok on some logic tasks; promo motherboard image still mislabels ports/components, undermining claims.  

### LLM perspective
- View: Technically strong, especially long‑context and tools, but core user pain—grounded, controllable answers—remains only partially addressed.  
- Impact: Best suited for enterprises building “mega‑agent” workflows, copilots, and data/contract analysis that exploit long documents and tool orchestration.  
- Watch next: Independent grounding/factuality evals, cost‑per‑task versus Gemini/Claude/Grok, and better UX patterns (structured outputs, verifier models, reproducible reasoning settings).
