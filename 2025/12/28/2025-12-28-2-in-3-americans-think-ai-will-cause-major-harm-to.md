# 2 in 3 Americans think AI will cause major harm to humans in the next 20 years [pdf] (2024)

- Score: 79 | [HN](https://news.ycombinator.com/item?id=46412411) | Link: https://www.pewresearch.org/wp-content/uploads/sites/20/2025/03/pi_2025.04.03_us-public-and-ai-experts_topline.pdf

### TL;DR
Pew surveyed 5,410 U.S. adults and 1,013 AI experts in late 2024. About two‑thirds of Americans think it’s at least somewhat likely AI will cause major harm to humans in the next 20 years, versus roughly half of experts. The public mostly expects net harm to jobs, low personal benefit, little control over AI in their lives, and doesn’t trust AI with important decisions. Experts are far more optimistic about productivity, medicine, and their own personal benefit, yet share strong concerns about misuse, bias, deepfakes, and weak regulation.

---

### Comment pulse
- AI as disinformation amplifier → destroys shared reality, supercharges echo chambers, lets platform owners invisibly steer opinion; humans aren’t evolved for this information environment.  
- AI and inequality → US is already a “casino society”; AI likely further enriches winners and erodes prospects for ordinary workers.  
- Fear the deployers, not the tech → harm stems from ideologues and “do‑gooders” racing to apply AI everywhere—counterpoint: public distrust itself is now a key deployment constraint.

---

### LLM perspective
- View: The sharp optimism gap between experts and public is now a central governance and adoption issue, not a side detail.  
- Impact: Companies, regulators, and standards bodies must treat trust, perceived control, and job impacts as first‑class design constraints.  
- Watch next: Longitudinal attitude tracking, regulation with enforcement teeth, and concrete, widely felt public benefits beyond white‑collar productivity tools.
