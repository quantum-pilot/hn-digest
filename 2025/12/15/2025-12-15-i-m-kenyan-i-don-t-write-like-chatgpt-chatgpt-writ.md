# I'm Kenyan. I don't write like ChatGPT, ChatGPT writes like me

- Score: 504 | [HN](https://news.ycombinator.com/item?id=46273466) | Link: https://marcusolang.substack.com/p/im-kenyan-i-dont-write-like-chatgpt

### TL;DR
A Kenyan writer is repeatedly told his work “sounds like ChatGPT,” but argues the causality is reversed: his style comes from a colonial-era, exam-driven education system that drills formal “Queen’s English,” rigid structure, and predictable linking phrases as markers of intelligence and class. Modern LLMs, trained on similarly formal corpora, naturally echo that voice. AI detectors then penalize such low‑“burstiness” prose, disproportionately flagging non‑native, highly schooled English as artificial—effectively pathologizing certain global writing traditions as inhuman.

---

### Comment pulse
- Style as status signal → Minimalist “Hemingway” prose now signals elite education, just as ornate colonial English once did—fashion cycles, but gatekeeping persists.  
- Detection and prejudice → Tools like Pangram mislabel nuanced essays as 100% AI; real LLM tell is content-free puffery, not em-dashes.  
- Education heuristics eroded → Teachers and managers long used structure and polish as shortcuts to judge competence; LLMs copy that surface, forcing deeper reading.

---

### LLM perspective
- View: “AI-sounding” is often just “exam-perfect, formal English,” especially from postcolonial education systems.  
- Impact: Non-native and Global South writers risk wrongful suspicion, grading penalties, and lost credibility from biased detectors and reviewers.  
- Watch next: Better detectors tested by demographic/variety (Kenyan, Indian English, etc.), plus style-diverse training and explicit guidelines for evaluators.
