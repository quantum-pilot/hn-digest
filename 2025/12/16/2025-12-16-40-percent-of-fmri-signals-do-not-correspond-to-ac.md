# 40 percent of fMRI signals do not correspond to actual brain activity

- Score: 381 | [HN](https://news.ycombinator.com/item?id=46288415) | Link: https://www.tum.de/en/news-and-events/all-news/press-releases/details/40-percent-of-mri-signals-do-not-correspond-to-actual-brain-activity

### TL;DR
Researchers at Technical University of Munich re‑examined the standard fMRI BOLD signal using a more detailed quantitative MRI model that estimates blood flow and oxygen metabolism. They report that in roughly 40% of brain regions, increased BOLD did not reflect increased metabolic activity and sometimes coincided with reduced activity, suggesting neurovascular coupling is often misinterpreted. Hacker News commenters connect this to long‑standing concerns about low signal‑to‑noise, statistical pitfalls, and hype in neuroimaging, while imaging practitioners stress limitations of the new “ground truth” and defend careful fMRI work.

---

### Comment pulse
- Neural signals are noisy, many EEG/fMRI results don’t replicate; deep learning can overfit artefacts — counterpoint: rigorous preprocessing and stats still yield robust findings.  
- Past critiques (Vul’s “voodoo correlations”, the dead‑salmon Ig Nobel) show how weak statistics and multiple‑comparison errors produced spurious fMRI activations.  
- Methodology worries: the TUM paper’s “quantitative BOLD” reference itself rests on complex models; without PET or invasive recordings, its 40% misinterpretation rate is uncertain.  

---

### LLM perspective
- View: Treat fMRI maps as indirect vascular readouts, not literal “neural activity pictures”; emphasize effect sizes, uncertainty, and converging evidence.  
- Impact: Human neuroscience, neuromarketing, and “mind‑reading” claims should be re‑audited, prioritizing studies cross‑validated with electrophysiology, PET, or invasive clinical recordings.  
- Watch next: Expect more multimodal experiments, open benchmarks linking BOLD to ground‑truth spiking, and stricter publication standards around statistics and preregistration.
