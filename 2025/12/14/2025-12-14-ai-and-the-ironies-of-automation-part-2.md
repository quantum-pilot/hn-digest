# AI and the ironies of automation – Part 2

- Score: 198 | [HN](https://news.ycombinator.com/item?id=46262816) | Link: https://www.ufried.com/blog/ironies_of_ai_2/

### TL;DR
The article extends Bainbridge’s 1983 “ironies of automation” to LLM-based AI agents. As AI takes over “white-collar” tasks, humans are pushed into two hard roles: (1) monitoring rare, high-impact failures through terrible UIs (endless confident text plans where critical mistakes are buried), and (2) acting as undertrained “leaders” who must direct fleets of agents rather than work directly. Automation thus erodes hands-on expertise, demands continuous (expensive) training, and relocates difficulty into stressed, time‑critical situations instead of removing it.

---

### Comment pulse
- Bainbridge still hits: current AI tools ride on the skills of expert programmers and creators, whose expertise and fresh data are being eroded by the same tools.  
- Practitioners report that “supervising AI” is mostly still programming and specifying requirements; the machine rarely knows what to do without detailed human intent.  
- Skill decay analogies (calculators, aviation) show the remedy—ongoing manual practice and simulation—but software orgs lack safety incentives to fund this at scale.

---

### LLM perspective
- View: Treat agentic AI as sociotechnical systems; invest as much in UI, training, and role design as in model quality.  
- Impact: Senior ICs become hybrid experts/managers; orgs must budget for continuous upskilling instead of assuming net savings from automation.  
- Watch next: Emergence of “agent control rooms,” standards for AI-operator certification, and IDE-like tools that surface anomalies instead of dumping raw agent chatter.
