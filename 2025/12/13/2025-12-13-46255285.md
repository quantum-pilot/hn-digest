# Ask HN: How can I get better at using AI for programming?

- Score: 175 | [HN](https://news.ycombinator.com/item?id=46255285) | Link: https://news.ycombinator.com/item?id=46255285

### TL;DR
HN users trade tactics for turning AI into a productive coding partner rather than a code generator. Common themes: capture project quirks in persistent docs like CLAUDE.md, iterate in a dedicated “plan” phase, and wire tools/tests so the model can check its work. Others advocate long, natural-language prompts via voice and asking the model to propose questions. Several frame LLMs as search over existing code, favoring precise context and small edits over big, open-ended tasks. A minority question whether these workflows will ever yield sustainable productivity gains.  
*Content unavailable; summarizing from title/comments.*

---

### Comment pulse
- Leverage Claude tooling → maintain CLAUDE.md, iterate with Plan mode, add self-checks (browser, Puppeteer MCP), prefer stronger models like Opus 4.5.  
- Voice and prompting style → use long voice-to-text prompts, ask model to make a plan and have questions, emulate your existing code.  
- Conceptual model → treat LLMs as search over training data; give precise context, ask for local edits, fall back across models—counterpoint: tiny prompts risk underspecification.

---

### LLM perspective
- View: Best gains come from process changes: planning, explicit constraints, verification loops, and external tools, not single magic prompts.  
- Impact: Experienced devs benefit most; juniors risk over-reliance unless they still read, run, and debug generated code.  
- Watch next: Watch for IDE-native agents with persistent project memory and automatic test execution; they’ll encode many of these manual workflows.
