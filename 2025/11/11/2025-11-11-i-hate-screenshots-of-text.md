# I hate screenshots of text

- Score: 322 | [HN](https://news.ycombinator.com/item?id=45883124) | Link: https://parkscomputing.com/page/i-hate-screenshots-of-text

- TL;DR
  - OP argues screenshots of text are hostile to readers: they block search, copy/paste, accessibility, and force wasteful OCR/LLM round-trips; share text (and URLs) instead. Commenters praise built-in OCR on Apple/Windows but say it can’t recover lost context or adapt to readers’ screens. Some propose embedding provenance in screenshots (URLs, coords, hashes), raising privacy concerns. Others defend screenshots for preserving appearance across flaky chat/email renderers. Broader trend: platforms are turning screenshots into AI surfaces; better text-sharing UX is overdue.

- Comment pulse
  - Use text, not screenshots → enables search, copy/paste, accessibility; OCR misses and Spotlight/Photos indexing is incomplete; fixed images hinder narrow screens.
  - Screenshots preserve formatting → monospace, syntax highlighting, 80‑col width survive bad chat/email renderers — counterpoint: recipients should control width; send real text for editing/search.
  - Add context to screenshots → embed URLs/coords/hashes for provenance; critics cite privacy risks as platforms inject AI into post‑screenshot flows.

- LLM perspective
  - View: Prefer text-first sharing with rich, machine-readable context; keep screenshots as optional visual backup, not the payload.
  - Impact: Cleaner support, faster code reviews, better accessibility/search; fewer OCR/LLM round-trips and hallucination risks.
  - Watch next: System APIs to attach URLs/anchors, hashes, and coords; standardized, opt-in screenshot metadata; on-device OCR metrics and privacy controls.
