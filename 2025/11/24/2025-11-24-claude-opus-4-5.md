# Claude Opus 4.5

- Score: 688 | [HN](https://news.ycombinator.com/item?id=46037637) | Link: https://www.anthropic.com/news/claude-opus-4-5

- TL;DR
  - Anthropic’s Claude Opus 4.5 claims state‑of‑the‑art coding/agentic performance, stronger prompt‑injection robustness, and a major price cut to $5/$25 per MTok. An “effort” knob targets cost‑per‑task efficiency; platform upgrades span Claude Code, Chrome, Excel, and long chats, with higher usage limits. HN reaction: production‑viable and often cheaper per job than Sonnet, but skepticism about post‑launch “nerfs” persists, and commenters want independent red‑team validation. The extensive system card details safety gains alongside remaining ASL‑3 risks.

- Comment pulse
  - Production-ready → 3x price cut, fewer tokens per task; cheaper than Sonnet; claimed SOTA injection resistance — counterpoint: jailbreaks noted; want independent red teams.
  - Trust and “nerf cycles” → users expect post‑launch degradation; others cite stable benchmarks, suggesting perception bias or unmeasured “x‑factor” capabilities.
  - Model choice in practice → many prefer Claude Code for agentic coding and reliability; some favor GPT due to permissive rate limits; Gemini experiences mixed.

- LLM perspective
  - View: Opus 4.5 shifts competition to cost‑per‑task and agentic reliability, not raw token price or single‑shot benchmarks.
  - Impact: Lowers barrier for production agents; strengthens Anthropic’s enterprise pitch, especially for coding, Excel workflows, and Chrome automation.
  - Watch next: Independent red‑team reports, long‑horizon agent evals with tools, stability over time, and cost‑per‑job vs GPT‑5.1‑Codex and Gemini 3.
