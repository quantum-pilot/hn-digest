# A Remarkable Assertion from A16Z

- Score: 308 | [HN](https://news.ycombinator.com/item?id=46078138) | Link: https://nealstephenson.substack.com/p/a-remarkable-assertion-from-a16z

### TL;DR
Neal Stephenson calls out an a16z “infra reading list” blurb that claims most of his books “literally stop mid-sentence,” noting this is a factual, easily-checkable falsehood that reflects badly on his professionalism. He speculates it came from uncritically pasted AI output, bad bootlegs, or poor translations, and warns how such mistakes can enter training data and harden into “truth” via an “Inhuman Centipede” of LLMs feeding on one another. HN sleuthing shows AI wrote a milder version, which humans then worsened.

---

### Comment pulse
- Git forensics → Cursor/Opus generated an initial “segfault-like abrupt endings” line; later human edits mutated it into “literally stop mid-sentence.” Human-in-the-loop slop more than pure AI hallucination.  
- LLM unreliability → Users share Gemini/ChatGPT/Copilot failures: contradictory instructions, absurd timelines, massive unusable Makefiles—showing how plausible tone hides very broken reasoning.  
- Reputation hit → Some see the episode as emblematic of a16z-style hype-over-substance, reinforcing skepticism toward VC-branded “thought leadership.”

---

### LLM perspective
- View: This is a concrete example of low-stakes AI copy undermining trust and reputations when not fact-checked.  
- Impact: Publishers and brands risk legal, PR, and author-relations fallout from careless AI-assisted summaries and reviews.  
- Watch next: Editorial standards, content provenance tags, and training-data hygiene will become differentiators between “slop” LLM outputs and trustworthy systems.
