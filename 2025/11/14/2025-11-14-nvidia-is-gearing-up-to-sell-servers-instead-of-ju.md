# Nvidia is gearing up to sell servers instead of just GPUs and components

- Score: 161 | [HN](https://news.ycombinator.com/item?id=45926439) | Link: https://www.tomshardware.com/tech-industry/artificial-intelligence/jp-morgan-says-nvidia-is-gearing-up-to-sell-entire-ai-servers-instead-of-just-ai-gpus-and-componentry-jensens-master-plan-of-vertical-integration-will-boost-profits-purportedly-starting-with-vera-rubin

- TL;DR
  - J.P. Morgan says Nvidia will shift with Vera Rubin (VR200) to selling fully built L10 compute trays—CPU, GPUs, memory, NICs, power, and liquid cooling—shrinking OEM design roles to rack integration and capturing more margin. Drivers: soaring GPU TDPs and complex boards, faster ramps via EMS. It’s unofficial. HN debates whether this is new (vs DGX) or deeper integration; flags lock-in/monopoly risk and possible impacts on Supermicro-like OEMs, plus speculation about PR timing and longer-term “compute-as-a-service” ambitions.

- Comment pulse
  - Clarification: Shift to L10 trays bundling CPU, GPUs, memory, NICs, power, liquid cooling → OEMs do rack-level integration, not server design.
  - Vertical integration boosts control and margins → rising lock-in, DGX-like mainframe model — counterpoint: hyperscalers prefer custom MGX/OCP designs and won’t fully cede racks.
  - Market angle: OEM margins compress; Supermicro exposure questioned; timing read as narrative management amid stock swings.

- LLM perspective
  - View: Standardized, liquid-cooled high-TDP trays centralize value in Nvidia modules; OEM differentiation shrinks to logistics and services.
  - Impact: ODM design revenue declines; EMS like Foxconn gain volume; hyperscalers trade faster ramps for less hardware flexibility.
  - Watch next: VR200 L10 BOM scope, per-GPU TDP confirmation, first adopter announcements, any antitrust scrutiny or OCP “open tray” alternatives.
