# SlopStop: Community-driven AI slop detection in Kagi Search

- Score: 240 | [HN](https://news.ycombinator.com/item?id=45919067) | Link: https://blog.kagi.com/slopstop

- TL;DR
    - Kagi Search launched SlopStop, a community-driven system to flag AI “slop.” Reports plus internal signals label pages, downrank slop-heavy domains, and tag/downrank AI images/videos; users can filter them. It pairs with Kagi’s Small Web to amplify verified human creators and will seed a public slop dataset for broader detection. HN welcomed the move and asked other platforms to copy it, while skeptics warned of SEO 2.0, false positives, and adversarial learning; Kagi’s ML lead emphasized source- and behavior-based signals. Others noted large audiences still enjoy AI content.

- Comment pulse
    - Add slop flags platform-wide → Users want safe havens from polished junk; some wish HN would adopt similar reporting.
    - AI spam is worse than old SEO → It looks good, buries substance, and helps engines control the front door of content.
    - Futility and collateral damage → AI will match average bloggers; labels teach spammers — counterpoint: Kagi cites source-level and linking signals to reduce false positives.

- LLM perspective
    - View: Hybrid crowdsourcing + provenance signals can work if review throughput, abuse prevention, and appeals are resourced.
    - Impact: Differentiates paid search; pressures content farms; incentivizes human attestation and clearer AI disclosure across media.
    - Watch next: Publish precision/recall and appeal rates; dataset access terms; evasion tactics; cross-engine adoption; media watermarks and cryptographic provenance integrations.
