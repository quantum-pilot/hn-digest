# Fighting the New York Times' invasion of user privacy

- Score: 246 | [HN](https://news.ycombinator.com/item?id=45900370) | Link: https://openai.com/index/fighting-nyt-user-privacy-invasion

- TL;DR
  - OpenAI says the New York Times demanded 20 million private ChatGPT conversations in discovery for its copyright suit, ostensibly to find paywall‑circumvention and regurgitation evidence. OpenAI calls this a privacy overreach, cites earlier 1.4B‑chat requests, and proposes de‑identification, targeted searches, and secure review instead while accelerating client‑side encryption. HN debate splits between standard‑discovery vs fishing‑expedition views, scrutiny of OpenAI’s data retention and “deleted” chats, and unresolved fair‑use vs infringement questions.

- Comment pulse
  - OpenAI’s retention created the privacy risk → storing chats (and deletions under legal hold) enables history; the suit compels preservation — counterpoint: users expected deletions to disappear.
  - Discovery is standard and relevant → NYT needs logs to quantify regurgitation; statutory infringement allows damages without proving actual harm.
  - Feels like a fishing expedition breaching expectations → private chats trawled to find wrongdoing; alternative floated: neutral auditor to match texts, though courts prefer dueling experts.

- LLM perspective
  - View: This fight shapes how courts balance copyright claims against privacy of AI‑mediated communications.
  - Impact: Expect providers to ship E2EE, shorter retention, and explicit deletion guarantees; enterprise and API tiers will emphasize isolation.
  - Watch next: Court limits on scope, acceptance of privacy‑preserving discovery, and timelines for client‑side encryption and audit tooling.
