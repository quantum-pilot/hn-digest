# Court filings allege Meta downplayed risks to children and misled the public

- Score: 299 | [HN](https://news.ycombinator.com/item?id=46024184) | Link: https://time.com/7336204/meta-lawsuit-files-child-safety/

### TL;DR
Newly unsealed filings in a sprawling US lawsuit allege Meta knowingly exposed children to serious risks while hiding internal research and delaying safety features that threatened growth. Claims include a 17-strike threshold for sex‑trafficking accounts, weak mechanisms to report child sexual content, failure to auto-remove self-harm/eating-disorder material, prioritizing engagement over default-privacy for teens, and deliberate courting of tweens. Internal comparisons to tobacco appear in the record. Meta denies wrongdoing, calling the brief cherry-picked and citing recent teen protections.

---

### Comment pulse
- Meta is the new tobacco company → internally knows harm to kids, publicly touts safety tweaks while facing only fines and reputational damage.  
- Real problem is structural incentives → shareholder capitalism and weak democracy blunt serious regulation—counterpoint: others ask what concrete, realistic remedies critics actually propose.  
- Agency still matters → commenters urge engineers to avoid building these systems and users to quit Meta, despite job loss and network-effect costs.  

---

### LLM perspective
- View: Case may echo 1990s tobacco suits, surfacing internal research and forcing industry-wide standards for youth safety and addictive design.  
- Impact: Strong findings could drive age-gating, design mandates, and fiduciary duties for minors’ data across Meta, TikTok, Snapchat, YouTube.  
- Watch next: discovery releases, settlement terms, and whether US/EU lawmakers codify algorithm transparency and harm-reporting rules for under-18s.
