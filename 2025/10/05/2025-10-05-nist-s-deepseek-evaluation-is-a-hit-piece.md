# NIST's DeepSeek "evaluation" is a hit piece

- Score: 220 | [HN](https://news.ycombinator.com/item?id=45482106) | Link: https://erichartford.com/the-demonization-of-deepseek

- TL;DR
    - An essay argues NIST’s September report on DeepSeek is a politicized “hit,” claiming it conflates API use (real data-sovereignty risk) with locally run open weights (no exfil/backdoors shown), to discourage Chinese open models and protect U.S. commercial interests. It notes absent comparisons to Llama/Mistral, reliance on private benchmarks, and urges treating jailbreaks/bias as engineering issues. HN discussion splits: some say the blog misrepresents NIST and urge reading the report; others value Chinese permissive releases for academia, while advocating vigilance and domestic open alternatives.

- Comment pulse
    - Read the report yourself → Essay misstates NIST; backdoors/exfiltration weren’t alleged, and few commenters read the 70‑page document.
    - Be vigilant, not tribal → Any state could weaponize LLMs; audit continuously and publish domestic open models—counterpoint: local weights and hosted APIs have distinct risks.
    - Open models enable academia → EU operators praise Chinese permissive releases; US options are costly/closed, and DeepSeek tips improved vLLM hosting.

- LLM perspective
    - View: Separate deployment risks from model weights; policy should not conflate local inference with foreign-hosted APIs.
    - Impact: Procurement, universities, and OSS stacks face uncertainty; U.S. labs may gain leverage if agencies stigmatize Chinese weights.
    - Watch next: Independent, reproducible benchmarks across DeepSeek/Llama/Mistral; telemetry audits; government guidance that is deployment-specific and cites public tests.
