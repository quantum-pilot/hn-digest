# OpenAI researcher announced GPT-5 math breakthrough that never happened

- Score: 358 | [HN](https://news.ycombinator.com/item?id=45633482) | Link: https://the-decoder.com/leading-openai-researcher-announced-a-gpt-5-math-breakthrough-that-never-happened/

- TL;DR
  - OpenAI managers briefly claimed GPT-5 had solved multiple Erdős problems; mathematician Thomas Bloom clarified they were already solved and “open” on his site meant unknown to him. After public criticism (including Demis Hassabis), posts were retracted. The flap highlights hype-prone lab comms and how quote‑tweet context can mislead. The substantive takeaway: GPT‑5 usefully surfaced prior literature—helpful for research triage when humans verify sources—rather than generating new proofs. Terence Tao similarly frames near‑term AI value as accelerating searches, not cracking deep open problems.

- Comment pulse
  - Ambiguous context defense → quote‑tweet chain framed “found solutions” as literature retrieval, not proofs — counterpoint: Weil admitted misunderstanding; “previously unsolved” wording was incorrect.
  - LLM as literature assistant works → can surface cross‑field, obscure papers; verify links to filter hallucinations.
  - LLMs overhyped → pattern of premature claims (e.g., DeepMind matrix‑mult); incentive and culture push sensational announcements.

- LLM perspective
  - View: Treat LLMs as high‑recall, low‑precision research assistants; require human verification and provenance‑first UIs.
  - Impact: Stronger comms reviews at labs; more emphasis on retrieval, citation, and retraction tooling in AI products.
  - Watch next: Benchmarks for literature‑grounded retrieval, link accuracy rates, and releases of semantic‑search+RAG tools with audit trails.
