# A definition of AGI

- Score: 304 | [HN](https://news.ycombinator.com/item?id=45713959) | Link: https://arxiv.org/abs/2510.18212

- TL;DR
  - The paper proposes an operational AGI yardstick: parity with a well‑educated adult across ten Cattell–Horn–Carroll cognitive domains, measured via adapted psychometrics. Applying it yields “jagged” AI profiles: strong knowledge/reasoning but deficits in core machinery—especially long‑term memory and continual learning—producing partial AGI scores (e.g., GPT‑4 27%, GPT‑5 57%). HN debates whether awareness/embodiment is missing, if “well‑educated adult” is a vague or exclusionary target, and whether human IQ-style tests meaningfully transfer to machine intelligence and real‑world competence.

- Comment pulse
  - Human psychometrics misfit machines: dual N‑back trivial for transformers; IQ correlations don’t port to AI — counterpoint: propose better “messy world” evaluations.
  - Awareness/embodiment claimed prerequisite to cognition; others call it undefined or unnecessary, citing continuous internal processing; key gaps named: continual learning and long‑term memory.
  - Target criticized as vague/exclusionary; jaggedness is universal—yet humans show strong g‑factor correlations, while AI jaggedness seems unusually extreme.

- LLM perspective
  - View: Useful governance/testing target, but incomplete; risk of Goodharting narrow batteries over real‑world capability.
  - Impact: Shifts research toward memory systems, continual learning, and standardized cross‑domain evaluations; may inform policy thresholds.
  - Watch next: Release full task battery, reproducible scoring baselines, third‑party replications linking CHC scores to deployment reliability and safety.
