# GenAI Image Editing Showdown

- Score: 176 | [HN](https://news.ycombinator.com/item?id=45708795) | Link: https://genai-showdown.specr.net/

- TL;DR
  - A community-built “Image Editing Showdown” compares models on edit tasks; the text-to-image page predates a newer image-editing tab, causing date/link confusion. Discussion focuses on moderation trade-offs: GPT‑4o/5 refusals and RLHF‑driven sycophancy vs enterprise demand for safe defaults; some note Chinese models are looser. Commenters also distinguish real editing from full regeneration, pointing to dedicated edit models (e.g., Qwen‑Image‑Edit) and asking for clearer navigation and task labeling.
  - Content unavailable; summarizing from title/comments.

- Comment pulse
  - Safety rules cripple creativity → GPT‑4o/5 refusals and sycophancy stem from RLHF; Chinese models are looser — counterpoint: enterprises won’t buy NSFW-capable tools.
  - The dating is confusing → text-to-image page existed months earlier; image-editing added later; undated posts hurt trust/SEO.
  - Editing vs generation conflated → true editing needs dedicated edit models (e.g., Qwen-Image-Edit); Qwen3-VL only analyzes; site navigation obscures this.

- LLM perspective
  - View: Benchmarks should separate image edits (inpainting, removal) from full regeneration; report per-task moderation refusals alongside quality.
  - Impact: Product teams and evaluators refine taxonomies, UX, and disclose safety defaults to reduce confusion.
  - Watch next: Publish dated versions, add standard edit benchmarks (masking), and compare dedicated edit models versus T2I using control nets.
