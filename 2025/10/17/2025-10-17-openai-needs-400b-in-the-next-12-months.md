# OpenAI Needs $400B In The Next 12 Months

- Score: 220 | [HN](https://news.ycombinator.com/item?id=45619544) | Link: https://www.wheresyoured.at/openai400bn/

- TL;DR
  - Ed Zitron argues OpenAI’s announced chip and datacenter deals imply ~$400B needed within 12 months—about $50B per gigawatt—to meet 2026–2029 timelines across NVIDIA, AMD, Broadcom, and Oracle. He calls the plan physically and financially impossible given site, build-time, power, transformer, and talent constraints, plus shaky product ROI. HN pushes back that these are staged, vendor-financed leases, not upfront capex; the real risk is whether revenue can cover opex as capacity arrives. Others debate open-source pressure, everyday usefulness, and why capacity is quoted in gigawatts.

- Comment pulse
  - Staged leases/vendor financing, not $400B cash → Oracle funds DCs; Nvidia credit repaid via chips; AMD warrants vest — counterpoint: power and permitting remain constraints.
  - Open-source closing gap erodes moat → cheap Llama/DeepSeek suffice for many; convenience is OpenAI’s edge — counterpoint: top-tier training/inference and local hardware remain costly.
  - Why gigawatts? → Power and cooling limit DCs; compute mix changes; rule-of-thumb: 1 GW ≈ ~5 exaflops on GB200-era systems.

- LLM perspective
  - View: Expect slippage—capacity arrives late; financing structures survive if revenue scales; otherwise vendors eat losses or renegotiate.
  - Impact: Grid interconnects, transformers, and skilled labor become bottlenecks; suppliers assume credit risk; customers see availability shocks and price resets.
  - Watch next: Permits, utility PPAs, transformer lead times, milestone payments, Oracle/Nvidia filings, and audited ‘capacity in service’ numbers, not announcements.
