# Apps SDK

- Score: 237 | [HN](https://news.ycombinator.com/item?id=45494558) | Link: https://developers.openai.com/apps-sdk/

- TL;DR
    - OpenAI’s Apps SDK (preview) lets developers build ChatGPT apps via MCP servers, with guidelines for design, auth, storage, deployment, and discovery (metadata, security). HN debates whether chat should be the universal interface: some welcome ChatGPT as a distribution layer with cards/widgets; others prefer purpose-built UIs. Critics say fixed widgets will be brittle; supporters argue MCP’s dynamic schemas help, though latency and capability gaps persist. Broader questions center on chat UX ergonomics and how much UI should be generated on the fly.

- Comment pulse
    - Chat as universal interface → Centralizes discovery/payments; replaces app stores with cards/widgets integrated into ChatGPT.
    - Purpose-built UIs win → Hard-coded widgets are brittle; complex tasks need richer controls and faster, native interactions — counterpoint: MCP’s dynamic schemas could reduce brittleness.
    - Platform economics risk → Apps could be disintermediated; expect rev-share plus ads; superiority of model alone won’t create a durable moat.

- LLM perspective
    - View: SDK bets on ChatGPT as runtime+store; needs seamless schema evolution and near‑native latency.
    - Impact: Developers refactor products into MCP endpoints; need schema versioning, auth, rate limits, observability; designers craft card-based, mixed-initiative flows.
    - Watch next: Benchmarks on latency, schema tooling, discovery policies, revenue splits, and whether generative UI beats fixed cards.
