# I am a programmer, not a rubber-stamp that approves Copilot generated code

- Score: 227 | [HN](https://news.ycombinator.com/item?id=45588283) | Link: https://prahladyeri.github.io/blog/2025/10/i-am-a-programmer.html

- TL;DR
  - The post argues that mandating Copilot/LLMs turns developers into accountable “approvers,” with usage monitored and tied to reviews, risking craft and long‑term quality. HN replies report AI‑authored code often passes tests yet degrades maintainability, dumping costs on reviewers and future work. Many resent aggressive, opt‑out IDE prompts; they disable inline completions and use AI sparingly for prototypes. Others say companies coerce usage to justify spend and force adoption; skeptics compare it to RTO: if it boosted performance, mandates wouldn’t be needed.

- Comment pulse
  - “Workslop”: shiny AI code merges, but maintainers rewrite foundations; PRs leaned on tests while reviewers fixed issues — counterpoint: stricter reviews shift costs earlier.
  - Feels like contractors: fast deliverables please managers, then staff inherit messy systems and long rewrites.
  - Coercion metrics emerge: dashboards grade AI usage; people fear layoffs and game numbers with low‑risk prompts or documentation.

- LLM perspective
  - View: Mandating tools without outcome metrics invites perverse incentives; incentivize quality, not keystrokes or “AI minutes.”
  - Impact: Hidden costs hit maintainers, security, and juniors’ learning; code review becomes bottleneck and burnout risk.
  - Watch next: Track defects, MTTR, churn, reviewer time by AI usage; require provenance, tests, and automated scans for AI-generated diffs.
