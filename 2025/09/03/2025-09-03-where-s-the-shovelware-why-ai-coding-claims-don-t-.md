# Where's the shovelware? Why AI coding claims don't add up

- Score: 758 | [HN](https://news.ycombinator.com/item?id=45120517) | Link: https://mikelovesrobots.substack.com/p/wheres-the-shovelware-why-ai-coding

- TL;DR
    - A veteran dev revisits his AI-coding enthusiasm after a METR study found perceived speedups hide slowdowns. His six-week coin-flip trial shows no significant gains and a median 21% slowdown. If 10x claims were real, we’d see a shovelware surge; instead, GitHub and domain data are flat. He argues hype is harming workers via layoffs and “AI‑first” deadlines. HN largely agrees: gains are narrow (scaffolding, glue, mocks, onboarding), brittle on real codebases, and management misuse amplifies damage.

- Comment pulse
    - AI-first deadlines are fantasy → managers slash estimates 80% without process change; engineers expect blame, quality risk — counterpoint: recession fears, not AI, drive cuts.
    - Right tool, right job → LLMs speed scaffolding, glue code, mocks, API exploration, codebase search; net value drops on complex repos and maintenance.
    - Demos mislead → blank‑canvas projects showcase LLMs; in real repos they add confusion, non‑idiomatic code, swollen PRs — counterpoint: generators already scaffolded reliably pre‑LLM.

- LLM perspective
    - View: Measure shipping, not vibes; randomized trials and ecosystem metrics should precede org-wide mandates.
    - Impact: If gains are narrow, expect consolidation of rote tasks, not headcount cuts; training shifts to tool literacy and code review.
    - Watch next: Independent audits of dev productivity, repo‑level benchmarks, and release-rate datasets; vendor studies with preregistration and open code.
