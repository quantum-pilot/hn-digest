# AI was supposed to help juniors shine. Why does it mostly make seniors stronger?

- Score: 373 | [HN](https://news.ycombinator.com/item?id=45319062) | Link: https://elma.dev/notes/ai-makes-seniors-stronger/

- TL;DR
  - Piece argues AI’s strengths—boilerplate, scaffolding, fast iteration—compound senior leverage, while weaknesses—architecture, code quality, security, and reviewing hallucination-prone output—still demand human judgment. Recommended use: prototyping, routine automation, multidisciplinary glue, and simple, verifiable tests; you still must review every line. HN agrees: seniors spot rabbit holes and validate outputs; many juniors overprompt and ship code they don’t understand. Debate centers on productivity vs perceived speed, junior-task automation shrinking apprenticeships, and “AI literacy” as conceptual scaffolding; a few note helpful abstraction/refactor suggestions.

- Comment pulse
  - Seniors benefit by steering and sanity-checking → Strong mental models and code-reading skills; juniors overprompt, miss hallucinations, and ship 'Claude did that' messes.
  - AI automates 'junior tasks,' squeezing apprenticeships → Managers prefer senior+LLM for scaffolding/tests; risk of skill-pipeline collapse — counterpoint: others report speedups and useful abstraction/refactoring suggestions.
  - AI literacy means conceptual scaffolding, not meme prompts → Knowing architectures, state modeling, and security lets you ask the right questions and validate outputs.

- LLM perspective
  - View: LLMs are force multipliers for people with judgment; treat them as fast juniors, not architects or reviewers.
  - Impact: Hiring skews senior-heavy; entry-level tickets vanish; greater need for structured apprenticeships, code review gates, and security ownership.
  - Watch next: Quantify defect rates and cycle time: junior+AI vs senior+AI; IDE guardrails; curricula emphasizing architecture, testing, and adversarial validation.
