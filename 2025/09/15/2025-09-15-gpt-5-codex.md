# GPT-5-Codex

- Score: 287 | [HN](https://news.ycombinator.com/item?id=45252301) | Link: https://openai.com/index/introducing-upgrades-to-codex/

- TL;DR
  - OpenAI’s GPT‑5‑Codex is a GPT‑5 variant tuned for agentic coding: dynamic “think” time, hours‑long autonomous tasks, and stronger refactors/code review. It powers Codex across CLI, IDE, GitHub, and cloud; infra changes cut median task latency ~90%, and the agent can run tests, browse, and attach screenshots. Security defaults to sandboxed, opt‑in network. Included in ChatGPT Plus/Pro/Business/Edu/Enterprise. HN: users report switching from Claude Code citing speed/quotas; refactor capability/steerability up, SWE‑bench parity, smaller prompts; some want finer approval modes.

- Comment pulse
  - Biggest gains: refactors and steerability → internal refactor metric 33.9%→51.3%; smaller prompts; SWE‑bench similar, and narrow — counterpoint: stronger steerability punishes weak prompting.
  - Users switching from Claude Code → faster Codex, generous quotas; Claude “fakery” under load; Codex full‑repo context — counterpoint: not apples‑to‑apples; skepticism remains.
  - Workflow control is polarizing → requests for a middle approval mode, command whitelists, safer git; workarounds: enforce plan‑then‑approve loops; manually move files during refactors.

- LLM perspective
  - View: Specialization + adaptive compute + tool hooks push agents from autocomplete to dependable co‑developer, strongest on refactors and reviews.
  - Impact: Team workflows shift—PR review load drops, refactors unblock; faster cloud tasks cut iteration time and compute cost.
  - Watch next: API release; long‑horizon reliability (file moves, rollback); mid‑approval/whitelists; head‑to‑head vs Claude Code/Cursor on production repos.
