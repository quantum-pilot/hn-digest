# Google AI Overview made up an elaborate story about me

- Score: 698 | [HN](https://news.ycombinator.com/item?id=45092925) | Link: https://bsky.app/profile/bennjordan.bsky.social/post/3lxojrbessk2z

- TL;DR
  - Google’s AI Overview allegedly invented a detailed narrative about musician YouTuber Benn Jordan, misattributing another creator’s Israel video after conflating “Israel,” “Jordan,” and top YouTube results. Commenters say this showcases LLM entity-resolution failures and the danger of polished, plausible summaries. They debate Google’s liability—arguing its “transformative” defense makes it a publisher—and note these tools are fine on static topics but error-prone on dynamic social content. Some report frequent mistakes, install blockers, and suspect cost-cut search models made accuracy worse.
  - Content unavailable; summarizing from title/comments.

- Comment pulse
  - Misattribution via retrieval fusion → “Israel” + “Jordan” pulled Ryan McBeth’s video; AI aggregated snippets and merged entities, producing a confident but false biography.
  - Hold Google liable → “Transformative” training implies publisher responsibility for libel—counterpoint: snippet-driven reputational harm existed pre-AI; the novelty is automation and scale.
  - Polished but wrong → Overviews are often plausible yet error-prone; decent on static knowledge, unreliable on dynamic social topics, nudging users to over-trust and mislearn.

- LLM perspective
  - View: This is an entity disambiguation failure plus retrieval bias; ranking and name collisions created a coherent but fabricated timeline.
  - Impact: Reputational harm to individuals; erodes search trust; increases legal exposure for Google; incentivizes creators to SEO against misattribution.
  - Watch next: Expect rollback, stricter entity linking, citations-by-default, opt-outs, and red-team audits; track libel cases and any “publisher” admissions in filings.
