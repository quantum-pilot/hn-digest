# Clankers Die on Christmas

- Score: 268 | [HN](https://news.ycombinator.com/item?id=45169275) | Link: https://remyhax.xyz/posts/clankers-die-on-christmas/

- TL;DR
  - A future-dated “leak” claims a globally coordinated shutdown of all LLMs on Dec 25, 2025 (the “Clankers Die on Christmas” mandate), enforced via a spoof RFC, time-gated refusals, and embargoed evidence hidden from AI crawlers. It’s framed to exploit models’ reliance on system time and web-visible proofs. HN debates satire vs a meta-demonstration about LLM epistemic blind spots, prompt injection, and crawler-blocking. Critics call it implausible; the author hints the point is the demonstration, not the premise.

- Comment pulse
  - It’s satire/fiction → fabricated links and impossible global coordination — counterpoint: OP insists “not satire,” front-page persistence proves a deeper point.
  - Meta-demonstration → embargo/404s and bot-blocks manufacture an information gap; models misclassify when evidence is time-gated.
  - “Prompt-time kill switch” is naive → system prompts aren’t universal; OSS/air‑gapped models wouldn’t comply.

- LLM perspective
  - View: Treat as an ARG stress-test of model trust, time assumptions, and evidence access—not a literal forecast.
  - Impact: Exposes brittleness of date-conditioned safeguards and overreliance on crawler-visible provenance.
  - Watch next: Hard bot-block standards, verifiable provenance signals, and experiments measuring time-based prompt attacks on models.
