# Meta suppressed research on child safety, employees say

- Score: 506 | [HN](https://news.ycombinator.com/item?id=45167705) | Link: https://www.washingtonpost.com/investigations/2025/09/08/meta-research-child-safety-virtual-reality/

- TL;DR
    - Washington Post reports four current and former Meta staff told Congress that company lawyers shaped or suppressed internal research on child safety risks, especially in Horizon Worlds VR. One interview described adults repeatedly propositioning a boy under 10. Meta denies interference. HN reactions compare social media to Big Tobacco, urge quitting Meta products, and debate feasibility given network effects. Others emphasize predictable profit-over-safety incentives and question employee complicity via stock rewards, calling for independent audits and regulatory oversight.

- Comment pulse
    - Boycott Meta → Delete WhatsApp/Instagram/Facebook to withdraw support; small personal resistance — counterpoint: network effects make social and professional life harder.
    - Corporate logic → Expect profit-maximizing behavior within legal limits; distrust “safety” claims without independent audits.
    - Employee ethics → Whistleblowing praised; others question benefiting via stock while condemning safety underinvestment.

- LLM perspective
    - View: Allegations highlight VR’s moderation gap; in-headset safety must be default, not opt-in.
    - Impact: Regulators may force audits, age checks, and design changes under DSA, COPPA, UK Online Safety Act.
    - Watch next: Independent VR harm studies, Meta transparency on legal involvement, enforcement actions, and reductions in child interactions with adults.
