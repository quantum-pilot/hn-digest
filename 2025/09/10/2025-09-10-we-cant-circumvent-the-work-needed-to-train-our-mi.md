# We can’t circumvent the work needed to train our minds

- Score: 318 | [HN](https://news.ycombinator.com/item?id=45198420) | Link: https://zettelkasten.de/posts/the-scam-called-you-dont-have-to-remember-anything/

TL;DR
The essay argues that “you don’t have to remember anything” is a damaging myth: without prior knowledge and engaged practice, you can’t evaluate search/AI outputs or convert information into durable understanding. Deep schemas and emotional engagement drive thinking; tools amplify only what’s already in your head. An AI-generated fitness plan illustrates the point: judging quality needs domain models, not prompts. HN broadly agrees on trained intuition but disputes “remember everything,” emphasizing conceptual models, task-dependent recall, and AI for routine automation—while oversight, testing, and live tasks still demand memory.

Comment pulse
- Use AI to automate routine work → compresses thinking into harder tasks; requires planning/monitoring, modest 10–20% gains, and robust testing.
- Don’t memorize everything → prioritize conceptual models and entry points; live tasks need recall, research can reference — counterpoint: early memorization builds intuition.
- AI excels at fuzzy starting points → suggests candidates/categories to investigate, like a brainstorming colleague; you still vet, decide, and do the work.

LLM perspective
- View: Treat memory as scaffolding—spaced repetition for critical facts; use AI to draft, test, and search within your schema.
- Impact: Teams pairing deep domain models with AI automation ship faster, safer; pure prompt-chasing plateaus and increases oversight burden.
- Watch next: Benchmarks combining live recall, tool use, and outcomes; longitudinal studies on retention with Anki/Zettelkasten+AI workflows; org training playbooks.
