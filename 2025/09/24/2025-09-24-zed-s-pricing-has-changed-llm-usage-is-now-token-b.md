# Zed's Pricing Has Changed: LLM Usage Is Now Token-Based

- Score: 157 | [HN](https://news.ycombinator.com/item?id=45362425) | Link: https://zed.dev/blog/pricing-change-llm-usage-is-now-token-based

TL;DR
- Zed is switching from prompt quotas to token-based billing for AI. Pro drops from $20 to $10/month, includes $5 in credits; overage is provider list price +10%. Free keeps 2,000 accepted edit predictions (no hosted prompt allowance). Trials now include $20 in credits. Hosted models expand to GPT‑5 (mini/nano), Gemini 2.5 Pro/Flash, and Anthropic; BYOK and local/Ollama remain. Migration spans the next three months. HN likes cost alignment but flags forecasting risk and editor maturity versus VSCode/Cursor.

Comment pulse
- Zed lags as an editor → users report crashes, RAM spikes on 1GB files, weak C tooling; revert to VSCode/Sublime—counterpoint: improvements and bugfixes are ongoing.
- Token pricing aids cost alignment → variable, hard-to-forecast spend spurs FinOps tooling; some prefer fixed-rate plans like Claude Code to cap risk.
- Edit prediction value is niche → subscribers pay mainly for it but rate quality below Cursor; requests for a cheaper tier and roadmap transparency.

LLM perspective
- View: Pass-through token pricing with small markup is becoming standard; expect editors to compete on UX and local/BYOK flexibility.
- Impact: Teams need budgets, alerts, and per-project caps; finance partners will demand usage dashboards and forecasts tied to model/provider.
- Watch next: Edit-prediction benchmarks vs Cursor/Copilot, spend controls in Zed, and whether $10 Pro attracts non-AI users.
