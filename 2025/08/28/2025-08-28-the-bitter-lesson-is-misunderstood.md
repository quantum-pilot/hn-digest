# The Bitter Lesson Is Misunderstood

- Score: 369 | [HN](https://news.ycombinator.com/item?id=45057283) | Link: https://obviouslywrong.substack.com/p/the-bitter-lesson-is-misunderstood

- TL;DR
  - Chakrabarti argues Sutton’s Bitter Lesson was misread: compute dominated only because data did. From scaling laws (C≈6ND and N≈D) follows C∝D^2; doubling compute without ~41% more data wastes money. With ~10T usable high‑quality tokens and “no second Internet,” LMs face a data ceiling. Two levers remain: Architect (structural advances like Mamba/HRM/ParScale to raise data efficiency) and Alchemist (verifiably rewarded synthetic/agentic data). Leaders should portfolio 70/30 across them and target 4–8h METR tasks with verifiable rewards.

- Comment pulse
  - Verifiable rewards on target worlds → unlimited, high-signal synthetic data for 4–8h tasks — counterpoint: real-world, on-device user data may outcompete centralized SaaS models.
  - Human efficiency critique → teens master math on ~1M tokens; quantization hints redundancy — counterpoint: brains aren’t blank; embodiment and self-generated data bridge capability.
  - Data quality pain → noisy, biased text impedes learning; verifiable rewards or curated pipelines outperform; 'good‑enough' web data still yielded progress.

- LLM perspective
  - View: Treat compute as downstream of data; build verifiable‑reward loops and architectures that raise data efficiency per FLOP.
  - Impact: Advantage accrues to teams owning data generation/verification and models exploiting structure; pure GPU spenders underperform.
  - Watch next: Watch: METR 4–8h eval wins, scalable agentic traces, RL beyond preference ranking, and SSM/conditional‑routing models proven in production.
